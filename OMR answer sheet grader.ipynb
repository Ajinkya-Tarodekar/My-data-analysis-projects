{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50399fbc-5b51-492c-ab7b-3b4bc3c5a18f",
   "metadata": {},
   "source": [
    "# PART 1: SCANNING OMR SHEETS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb96785c-6b30-4497-93dc-7ad7dc4c8979",
   "metadata": {},
   "source": [
    "## FUNCTION TO DRAW RECTANGLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "403fa401-a391-4eea-b96d-bb69973894c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def drawRec(biggestNew, mainFrame):\n",
    "        cv2.line(mainFrame, (biggestNew[0][0][0], biggestNew[0][0][1]), (biggestNew[1][0][0], biggestNew[1][0][1]), (0, 255, 0), 10)\n",
    "        cv2.line(mainFrame, (biggestNew[0][0][0], biggestNew[0][0][1]), (biggestNew[2][0][0], biggestNew[2][0][1]), (0, 255, 0), 10)\n",
    "        cv2.line(mainFrame, (biggestNew[3][0][0], biggestNew[3][0][1]), (biggestNew[2][0][0], biggestNew[2][0][1]), (0, 255, 0), 10)\n",
    "        cv2.line(mainFrame, (biggestNew[3][0][0], biggestNew[3][0][1]), (biggestNew[1][0][0], biggestNew[1][0][1]), (0, 255, 0), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba74b6a-7f8c-4cac-ac5e-bca71db41431",
   "metadata": {},
   "source": [
    "## IMAGE PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3838232-d4de-4f65-a3cb-8095bc46bf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing\n",
    "img = cv2.imread('blanksheet 5.jpg') #read image\n",
    "img = cv2.resize(img, (int(480*2), int(640*2)))\n",
    "w, h = 480, 640\n",
    "imgWarp = img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5afaec23-0867-49e0-a9c7-39f6070e1f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "GrayImg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)                #converting to grayscale\n",
    "BlurredFrame = cv2.GaussianBlur(GrayImg, (5, 5), 1)           #applying gaussian blur to smooth the image over\n",
    "CannyFrame = cv2.Canny(BlurredFrame, 190, 190)                 #the smoothened picture's boundaries are detected\n",
    "\n",
    "contours, _ = cv2.findContours(CannyFrame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#only detects external contour i.e edges and fixes the 4 vertices of the paper\n",
    "\n",
    "ContourFrame = img.copy() #creating a copy\n",
    "ContourFrame = cv2.drawContours(ContourFrame, contours, -1, (255, 0, 255), 4) #contour drawn in magenta colour of 4 pixel thickness\n",
    "CornerFrame = img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "114dd7e3-710f-4e02-a1ab-7125759f9981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the biggest contour\n",
    "maxArea = 0 #initializing the value to 0\n",
    "biggest = [] #making an empty list\n",
    "for i in contours :\n",
    "    area = cv2.contourArea(i)  #calculating area enclosed inside the contour\n",
    "    if area > 500 :\n",
    "        peri = cv2.arcLength(i, True)\n",
    "        edges = cv2.approxPolyDP(i, 0.02*peri, True)  #approximating the perimeter and the contour\n",
    "        if area > maxArea and len(edges) == 4 :\n",
    "            biggest = edges\n",
    "            maxArea = area\n",
    "\n",
    "if len(biggest) != 0 : #if the list is not empty\n",
    "    \n",
    "    biggest = biggest.reshape((4, 2))\n",
    "    biggestNew = np.zeros((4, 1, 2), dtype= np.int32) #array to store coordinates\n",
    "    add = biggest.sum(1)\n",
    "    \n",
    "    biggestNew[0] = biggest[np.argmin(add)]\n",
    "    biggestNew[3] = biggest[np.argmax(add)]\n",
    "    dif = np.diff(biggest, axis = 1)\n",
    "    biggestNew[1] = biggest[np.argmin(dif)]\n",
    "    biggestNew[2] = biggest[np.argmax(dif)]\n",
    "    drawRec(biggestNew, CornerFrame)           #find coords of each corner and draw the rectangle\n",
    "    \n",
    "    CornerFrame = cv2.drawContours(CornerFrame, biggestNew, -1, (255, 0, 255), 25)\n",
    "    pts1 = np.float32(biggestNew)                           #gets the detected rectangle's corners\n",
    "    pts2 = np.float32([[0, 0], [w, 0], [0, h], [w, h]])     #coordinates of new perspective\n",
    "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    imgWarp = cv2.warpPerspective(img, matrix, (w, h))      #flattens the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d032e7-bfa8-4f98-bea7-46994037bdf6",
   "metadata": {},
   "source": [
    "## SHOWING THE STAGES OF TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0822334e-dbf5-4cf7-b44a-b6f6ef9625da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Image saved successfully.\n"
     ]
    }
   ],
   "source": [
    "#saving\n",
    "\n",
    "success = cv2.imwrite(\"StudentName.jpg\", imgWarp)\n",
    "\n",
    "if success:\n",
    "    print(\"Success: Image saved successfully.\")\n",
    "else:\n",
    "    print(\"ERROR: Save Failed. Please Check for errors in the program or the input image!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a6aee1c-47a1-4f5c-b5f3-ee5beda7438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizing\n",
    "img = cv2.resize(img, (480, 640))\n",
    "GrayImg = cv2.resize(GrayImg, (480, 640))\n",
    "BlurredFrame = cv2.resize(BlurredFrame, (480, 640))\n",
    "CannyFrame = cv2.resize(CannyFrame, (480, 640))\n",
    "ContourFrame = cv2.resize(ContourFrame, (480, 640))\n",
    "CornerFrame = cv2.resize(CornerFrame, (480, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "522aa06d-3e27-492b-816e-a09034916474",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [img, GrayImg, BlurredFrame, CannyFrame, CornerFrame, ContourFrame, imgWarp]\n",
    "images_names = ['input', 'GrayImg', 'BlurredFrame', 'CannyFrame', 'CornerFrame', 'ContourFrame', 'output']\n",
    "x = 0\n",
    "for i in images:\n",
    "    cv2.imshow(images_names[x],i)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    x+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6e9d89-43c1-4cff-b0f1-e88db3d3aee4",
   "metadata": {},
   "source": [
    "# PART 2: SHEET VALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d360a499-941c-466e-a4b8-36297f5dfe7b",
   "metadata": {},
   "source": [
    "For this, we have to repeat the same procedure we had done in the document scanning code first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7df9cbbc-5dc0-4b8a-b80a-4a6e906ba49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "\n",
    "def drawRec(biggestNew, mainFrame):\n",
    "        cv2.line(mainFrame, (biggestNew[0][0][0], biggestNew[0][0][1]), (biggestNew[1][0][0], biggestNew[1][0][1]), (0, 255, 0), 20)\n",
    "        cv2.line(mainFrame, (biggestNew[0][0][0], biggestNew[0][0][1]), (biggestNew[2][0][0], biggestNew[2][0][1]), (0, 255, 0), 20)\n",
    "        cv2.line(mainFrame, (biggestNew[3][0][0], biggestNew[3][0][1]), (biggestNew[2][0][0], biggestNew[2][0][1]), (0, 255, 0), 20)\n",
    "        cv2.line(mainFrame, (biggestNew[3][0][0], biggestNew[3][0][1]), (biggestNew[1][0][0], biggestNew[1][0][1]), (0, 255, 0), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7774f920-faae-4c33-b232-86e02333d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Answers = np.array([       #The actual answers are stored in this numpy array\n",
    "        [0, 1, 0, 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1],\n",
    "        [0, 0, 0, 1],\n",
    "        [1, 0, 0, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 1, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5831507f-a326-47bc-a36b-955f7234e82a",
   "metadata": {},
   "source": [
    "# Getting the flattened image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f0609d4-a72a-4313-a8b3-083b0c8069c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('StudentName.jpg')\n",
    "img = cv2.resize(img, (int(480*2), int(640*2)))\n",
    "w, h = 480, 640\n",
    "imgWarp = img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c349bb7c-2ea2-4b71-8d25-413d1ea1a700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "GrayImg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "BlurredFrame = cv2.GaussianBlur(GrayImg, (5, 5), 1)\n",
    "CannyFrame = cv2.Canny(BlurredFrame, 190, 190)\n",
    "\n",
    "#drawing contours\n",
    "contours, _ = cv2.findContours(CannyFrame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "ContourFrame = img.copy()\n",
    "ContourFrame = cv2.drawContours(ContourFrame, contours, -1, (255, 0, 255), 4)\n",
    "CornerFrame = img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e38f668-c253-4936-be05-cb8b905f1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the biggest contour i.e detecting the OMR field\n",
    "maxArea = 0\n",
    "biggest = []\n",
    "for i in contours :\n",
    "    area = cv2.contourArea(i)\n",
    "    if area > 500 :\n",
    "        peri = cv2.arcLength(i, True)\n",
    "        edges = cv2.approxPolyDP(i, 0.02*peri, True)\n",
    "        if area > maxArea and len(edges) == 4 :\n",
    "            biggest = edges\n",
    "            maxArea = area\n",
    "\n",
    "if len(biggest) != 0 :\n",
    "    biggest = biggest.reshape((4, 2))\n",
    "    biggestNew = np.zeros((4, 1, 2), dtype= np.int32)\n",
    "    add = biggest.sum(1)\n",
    "    biggestNew[0] = biggest[np.argmin(add)]\n",
    "    biggestNew[3] = biggest[np.argmax(add)]\n",
    "    dif = np.diff(biggest, axis = 1)\n",
    "    biggestNew[1] = biggest[np.argmin(dif)]\n",
    "    biggestNew[2] = biggest[np.argmax(dif)]\n",
    "    drawRec(biggestNew, CornerFrame)\n",
    "    CornerFrame = cv2.drawContours(CornerFrame, biggestNew, -1, (255, 0, 255), 25)\n",
    "    pts1 = np.float32(biggestNew)\n",
    "    pts2 = np.float32([[0, 0], [w, 0], [0, h], [w, h]])\n",
    "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    imgWarp = cv2.warpPerspective(img, matrix, (w, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63fe3091-45cf-4d9b-8750-60964f8e1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizing\n",
    "img = cv2.resize(img, (480, 640))\n",
    "GrayImg = cv2.resize(GrayImg, (480, 640))\n",
    "BlurredFrame = cv2.resize(BlurredFrame, (480, 640))\n",
    "CannyFrame = cv2.resize(CannyFrame, (480, 640))\n",
    "ContourFrame = cv2.resize(ContourFrame, (480, 640))\n",
    "CornerFrame = cv2.resize(CornerFrame, (480, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7efb166d-7bec-4eb5-b5ee-d1552baca510",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgWarpGray = cv2.cvtColor(imgWarp, cv2.COLOR_BGR2GRAY)                #changing colour scheme to grayscale\n",
    "img_thresh = cv2.threshold(imgWarp,140,255, cv2.THRESH_BINARY_INV)[1]  #performing binary inverse on the pixels\n",
    "img_thresh_cropped = img_thresh[10:-10,10:-10]                         #removing border artifacts\n",
    "\n",
    "#cv2.imshow(\"img_thresh\", img_thresh_cropped)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf97cc80-2f1a-4e9b-aca5-b29a5afb1504",
   "metadata": {},
   "source": [
    "# SPLITTING THE IMAGE INTO SMALLER PARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "650babe2-6523-4a1a-acb8-a3c89af33f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the height of each slice\n",
    "slice_height = img_thresh_cropped.shape[0] // 8\n",
    "\n",
    "# Split the image into 8 horizontal slices\n",
    "horizontal_slices = [img_thresh_cropped[i * slice_height: (i + 1) * slice_height, :] for i in range(8)]\n",
    "\n",
    "# Display or process the horizontal slices as needed\n",
    "for i, slice_img in enumerate(horizontal_slices):\n",
    "    cv2.imshow(f\"Slice {i}\", slice_img)\n",
    "    cv2.waitKey(2000)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5bd9804-8864-4de2-8637-26ccb9569895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the vertical slices\n",
    "vertical_slices = []\n",
    "\n",
    "for horizontal_slice in horizontal_slices:\n",
    "    # Calculate the width of each vertical slice\n",
    "    slice_width = horizontal_slice.shape[1] // 4\n",
    "\n",
    "    # Split the horizontal slice into 4 vertical slices\n",
    "    for j in range(4):\n",
    "        vertical_slice = horizontal_slice[:, j * slice_width: (j + 1) * slice_width]\n",
    "        vertical_slices.append(vertical_slice)\n",
    "        \n",
    "        # Display or process the vertical slices as needed\n",
    "        cv2.imshow(f\"Vertical Slice {j} (from Horizontal Slice {i})\", vertical_slice)\n",
    "        cv2.waitKey(2000)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97010b61-8f57-4717-b1e3-86e7482c1dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Pixel Counts for Each Slice:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3135,  468,  306,  459],\n",
       "       [ 285, 2646,  300,  405],\n",
       "       [ 273,  126,  294,  411],\n",
       "       [ 285,  435, 1590,  414],\n",
       "       [ 267,  432,  294, 3315],\n",
       "       [ 819,  417,  282,  423],\n",
       "       [ 285,  438, 3186,  402],\n",
       "       [ 309,  444,  315, 3678]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of rows and columns\n",
    "num_rows, num_cols = 8, 4\n",
    "\n",
    "# Calculate the height and width of each slice\n",
    "slice_height = img_thresh_cropped.shape[0] // num_rows\n",
    "slice_width = img_thresh_cropped.shape[1] // num_cols\n",
    "\n",
    "# Initialize an empty numpy array to store white pixel counts\n",
    "white_counts = np.zeros((num_rows, num_cols), dtype=int)\n",
    "\n",
    "# Iterate through each slice\n",
    "for row in range(num_rows):\n",
    "    for col in range(num_cols):\n",
    "        # Extract the slice\n",
    "        slice_img = img_thresh_cropped[row * slice_height: (row + 1) * slice_height,\n",
    "                          col * slice_width: (col + 1) * slice_width]\n",
    "\n",
    "        # Count white pixels (assuming white is represented by intensity 255)\n",
    "        white_counts[row][col] = np.sum(slice_img == 255)\n",
    "\n",
    "# Print the white pixel counts for each slice\n",
    "print(\"White Pixel Counts for Each Slice:\")\n",
    "white_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0f4c5-b328-45c7-8d82-6ccda18e13ff",
   "metadata": {},
   "source": [
    "Since the image was subjected to grayscale and then binary inverse, the black pixels have been converted to white pixels and greater concentration of white pixels shall indicate the answer marked by the student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02e964bd-3d34-46dd-af5f-120e9846b071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9872ad93-8e68-49d0-b480-24cd517a6e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 0, 1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = white_counts\n",
    "for i in range(8):\n",
    "    for j in range(4):\n",
    "        if answers[i][j] < max(answers[i]):  #if maximum value is greater than current velue, store 0 in the cell\n",
    "            answers[i][j] = 0\n",
    "\n",
    "for i in range(8):\n",
    "    for j in range(4):\n",
    "        if answers[i][j] !=0:\n",
    "            answers[i][j] = 1  #if the value stored in the cell is not 0 then make it 1\n",
    "answers = np.array(answers)\n",
    "answers                       #this array displays the answers marked by the student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2554098a-4baf-4fcd-9fff-1c47ba04e3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_Answers #display model answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37fc00a1-1c66-4a79-b82b-181252ae5f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL GRADES SCORED =  18.0\n",
      "MISTAKEN QUESTIONS:\t\n",
      "Q.  1\n",
      "Q.  3\n",
      "Q.  4\n",
      "Q.  8\n"
     ]
    }
   ],
   "source": [
    "grade = 0.00\n",
    "mistakes = []\n",
    "for i in range(8):\n",
    "    if list(answers[i]) == list(Model_Answers[i]):\n",
    "        grade += 5.00 #add in 5 marks for every correct answer\n",
    "    else:\n",
    "        grade -= 0.5 #deduct 1/2 marks for every wrong answer\n",
    "        mistakes.append(i+1)\n",
    "print('TOTAL GRADES SCORED = ',grade)\n",
    "print('MISTAKEN QUESTIONS:\\t')\n",
    "for i in mistakes:\n",
    "    print(\"Q. \",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056174a4-535a-4b8b-835f-537fa25e656a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
